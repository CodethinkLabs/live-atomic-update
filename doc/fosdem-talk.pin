#!/usr/bin/env pinpoint

[duration=30]

--
Online Atomic updates
# Welcome to my talk about Online, or Live Atomic Updates.  My goal is
# to hopefully persuade some of you that it's something we should do,
# and hopefully a bit of collaboration, since I don't have a solution
# yet.

--
What do I mean by Online Atomic updates?
# First, what am I talking about?

--
Online - Updating a running system
# Online updates means Updating a running system, so there's no
# service outage.  So if you have to reboot to apply updates you are
# doing an offline update.

--
Atomic - All or nothing
# This is a bit more involved. You go from one version to another in
# one go.
# Traditional embedded does this with A/B partitioning and a watchdog
# for if the other partition doesn't boot.
# OSTree/Project atomic does this by rebooting into a different
# hardlink tree.
# CoreOS also does some form of atomic update, I haven't looked into
# it, but I think it still requires a reboot.
# At my day-job I work on a project called Baserock, which has
# different versions as btrfs subvolumes, and the bootloader picks
# which to use via the kernel command-line.

--
Why do you want Atomic updates?

•   System image based versioning

# As a result, you can version your system more easily, so you put
# together a set of known working combinations, and can easily
# identify what it is.
# Compared with package-based updates where you end up with a
# combinatorial explosion of what people are running, which makes
# debugging issues difficult.

--
Why do you want Atomic updates?
•   Non-atomic updates can leave your system unusable if you are
    interrupted mid-update.
    Per-file atomic update is not sufficient.

# Non-atomic package based updates aren't reliable, since if something
# goes wrong mid-package update, you can end up in an inconsistent
# state.
# There's tricks for ensuring you atomically update a single file,
# by writing it to disk, fsyncing and renaming it over the top of the
# old file.

-- [abi-safe-deps.png]

# But if you have interdependent files you need to find a
# safe order for replacing them.
# e.g. updating libc.so before other libraries, and relying on it
# providing a backwards-compatible ABI
# This requires packagers to declare a safe order, adding a lot of
# extra packaging work, and a slip-up in internal ABIs can leave you
# with a broken system when something goes wrong.

-- [abi-unsafe-deps.png]

# I'm not sure glibc is safe for this anyway, since there's symbols
# versioned to GLIBC_PRIVATE, which implies they don't keep internal
# ABI stability.

--

Proof of concept

# There's two parts to solving this:
# 1. Make your new version available
# 2. Make all your processes use the new version

-- [top] [baserock-version-layout.png]

PoC - Making software available

# In Baserock we make a CoW snapshot of an existing version and apply
# a delta. For example, we have a patch from "factory" to "version1".
# We create the "version1" rootfs snapshot above by snapshotting
# "factory/orig", applying the delta, calling that "version1/orig" and
# snapshotting "version1/run" from that, then synchronising the config.

-- [top] [mounted-baserock-version-layout.png]

PoC - Making software available

# Each version has a fstab for mounting the state volumes, mounting the
# directories like this:
# Sorry about the messy graph.

-- [mount-tree.png]

# The result is a filesystem tree somewhat like this. Beneath the node
# name is the subvolume name.
# You can see this if you run findmnt. You can do subtree mounts without
# btrfs if you do a `--bind` mount with the source of a subdirectory of
# an existing mount.

-- [mount-tree-new-mounted.png]

# There isn't a way to alter a subvolume mount to use a different subvolume,
# you have to do an entirely new mount, but because the `umount` API is
# path based, you can't mount the new version over the top and unmount the
# mount underneath.
# So instead I duplicate the mount tree with replacement mounts.

-- [mount-tree-pivoted.png]

# I can then do a `pivot_root` to make the new mount tree my root

-- [process-file-pointers.png]

# Unfortunately `pivot_root` won't make all your existing processes use the
# new versions of those files. It will only change the calling process'
# root and cwd, and only if they are both "/"

-- [process-file-pointers-corrected.png]

# So my proof of concept uses ptrace to make processes chroot, chdir and
# re-open directory file descriptors.
# You need to do this for every process in every mount namespace,
# and it becomes a headache, since you can't access the real /dev from
# every namespace.
# ptracing doesn't work because:
# 1.  Not all processes are ptraceable
# 2.  Most processes aren't allowed to chroot
# 3.  Processes don't like the inode number of their fds changing.
#     journald uses it to look-up which file descriptor was which when
#     it restarts itself.

-- [renameat2.png]

renameat2(…, RENAME_EXCHANGE)

# You can solve the need for changing the mount tree for every namespace
# and chroot by changing the filesystem.
# You *can* do a whole filesystem update by creating a parallel tree and
# doing a renameat2(..., RENAME_EXCHANGE) the root directories.
# However existing processes still have the old root, working directories
# and directory file descriptors.

-- [process-file-pointers-corrected.png]

New kernel interface for changing another process' file descriptors

# We could add a new kernel interface for altering process' open files
# so we don't need to ptrace, or require the process to have permissions
# to chroot, but that still doesn't solve the issue of the stat of directory
# fds changing.

--

Remaining approach - File system transactions

# One idea would be to add transactions to filesystems. 
# Btrfs has one form that can deadlock you if you're not careful, and
# there was a patch to specify a bunch of syscalls to run in a transaction
# but it didn't go anywhere.

--

Remaining approach - freeze all of userland during update

# You can freeze all processes in a freezer cgroup. You can get away
# without a fully atomic update if there's no concurrent users to worry
# about.

# This would give reasonable atomicity guarantees if you tell the
# bootloader to use a snapshot before you attempt to alter the current
# version, and you can attempt a roll-back if the application fails
# without crashing the machine.

--

Remaining approach - Pivot pid 1 and hand over all services

# We could make pid 1 (systemd) `pivot_root` into the new root and start
# new versions of services, with the old services handing over their
# state, like an irssi, apache or journald graceful restart.

# I don't consider this to be a useful contender, since it requires the
# whole linux userland to be able to serialise state and hand over file
# descriptors to a new process.

--

Remaining approach - Proxy filesystem

# Alternatively we could have a proxy filesystem that we can swap the
# backing mount for atomically, and have it keep the inodes stable.

# AUFS might be usable for this, as it has some inode mapping, but
# it doesn't let you remove a layer that has open files, so you can't
# clean up the old version until every process has re-executed itself.

--

Any questions?
