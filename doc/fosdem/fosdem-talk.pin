#!/usr/bin/env pinpoint
[transition=slide-left]

-- [duration=10]
Live Atomic updates

# Welcome to my talk about Online, or Live Atomic Updates.
#
# I generally prefer calling them Live, since Online is so
# overloaded a term that it also implies downloading software
# updates, while you could also sneakernet an update on.
#
# My goal is to hopefully bounce some useful ideas off people,
# and get some investment in the idea that we need to do this.

-- [duration=2]
What do I mean by Live Atomic updates?

# First, what am I talking about?

-- [duration=10]
Live/Online - Updating a running system

# Live updates means Updating a running system, so there's no
# service outage.
#
# So if you have to reboot to apply updates you are doing an
# offline update.

-- [duration=40]
Atomic - All or nothing

# Atomic is a bit more difficult to explain. You go from one
# version to another in one go, such that you only ever see the
# old version or the new version, not the intermediate states
# in-between.
#
# This is generally done by preparing the new version and
# instructing the bootloader to reboot into the new version,
# hence these updates are Atomic but not Live.
#
# Traditional embedded projects do this with A/B partitioning, so
# you install the new version to the partition you are not
# currently using; or live/recovery partitioning where you boot
# into recovery to apply the update (like android).
#
# OSTree/Project atomic does this by rebooting into a different
# hardlink tree.
#
# At my day-job I work on a project called Baserock, which has
# different versions as btrfs subvolumes, and the bootloader
# picks which to use via the kernel command-line, specifying a
# different subvolume.

-- [duration=25]
Why do you want Atomic updates?

•   System image based versioning

# You want system image based versioning to avoid the
# combinatorial explosion of all the possible versions that can
# be running, as if you do a package-based update you have all
# the different combinations of packages available.

-- [duration=20]
Why do you want Atomic updates?

•   Non-atomic updates can leave your system unusable if you are
    interrupted mid-update.
    Per-file atomic update is not sufficient.

# Non-atomic package based updates aren't reliable, since if
# something goes wrong mid-package update, you can end up in an
# inconsistent state.
#
# There's tricks for ensuring you atomically update a single
# file, by writing it to disk, fsyncing and renaming it over the
# top of the old file.

-- [abi-safe-deps.png] [duration=30]

# But if you have interdependent files you need to find a safe
# order for replacing them.
#
# e.g. updating libc.so before other libraries, and relying on it
# providing a backwards-compatible ABI
#
# This requires packagers to declare a safe order to update files
# in, adding a lot of extra packaging work, and a slip-up in
# internal ABIs can leave you with a broken system when something
# goes wrong.

-- [abi-unsafe-deps.png] [duration=15]

# I'm not sure even glibc is safe for this, since there's symbols
# versioned to GLIBC_PRIVATE, which implies they don't keep
# internal ABI stability, as if nothing else should be using
# them, it's "obvious" that you don't need to worry about keeping
# the ABI compatible.

-- [duration=8.425409]

Proof of concept

# So as any two files might need to be updated in-lockstep, we
# need to be able to update everything together.
#
# I tried to come up with something to provide an atomic
# filesystem update.
#
# There's two parts to solving an atomic filesystem update:
#
# 1.  Making all the data for the new version available
# 2.  Make all your processes use the new version

-- [baserock-version-layout.png] [top] [duration=30]

PoC - Making new versions available

# In Baserock we make a Copy-on-Write snapshot of an existing
# version and apply a delta. For example, we have a patch from
# "factory" to "version1".
#
# We create the "version1" rootfs snapshot above by snapshotting
# "factory/orig", applying the delta, calling that
# "version1/orig" and snapshotting "version1/run" from that, then
# synchronising the config.

-- [mounted-baserock-version-layout.png] [top] [duration=15]

# Each version has a fstab for mounting the state volumes,
# mounting the directories like this:
# 
# Sorry about the messy graph, I didn't have time to tweak
# graphviz or lay it all out manually.

-- [mount-tree.png] [duration=25]

# The result is a filesystem tree somewhat like this.
#
# I have listed the subvolume name beneath the node name.
#
# This is a path from the actual root of the filesystem to the
# "mount root".
#
# You don't need to be using btrfs to do this, as you can do this
# with a bind-mount, it just happens that btrfs lets you do it
# with one mount, while you need an initial mount then a bind
# mount to do it with other filesystems.
#
# You can see "mount root" by running `findmnt`, or looking at
# `/proc/self/mountinfo` yourself.

-- [mount-tree-new-mounted.png] [duration=30]

# There isn't a way to remount a subvolume mount to use a different
# subvolume, you have to do an entirely new mount.
#
# Because the `umount` API is path based, you can't mount the new
# version over the top and unmount the mount underneath.
# 
# So instead I duplicate the mount tree with replacement mounts,
# as shown in the graph.

-- [mount-tree-pivoted.png] [duration=15]

# I can then do a `pivot_root` to make the new mount tree my
# root.
# 
# This swaps the root mount point with that of the new tree's
# root mount mount and puts the old mount point somewhere useful
# that we can unmount later.
#
# You do a similar transition at every boot when you go from the
# early userland in your initramfs to your rootfs.

-- [process-file-pointers.png] [duration=20]

# Unfortunately `pivot_root` won't make all your existing
# processes use the new versions of those files.
#
# It will only change the calling process' root and cwd, and only
# if they are both "/".
#
# This is sufficient for early userspace as very few processes
# need to migrate to the rootfs without interruption, the only
# ones I can think of are storage or file-system daemons, and
# it's probably preferable for them to stay in the initramfs.

-- [process-file-pointers-corrected.png] [duration=45]

# We however, need every process to move to the new tree, so my
# proof of concept uses ptrace to make processes chroot, chdir
# and re-open directory file descriptors.
#
# You need to do this for every process in every mount namespace,
# and it becomes a headache, since you can't access the real /dev
# from every namespace.
#
# Injecting code to make processes move themselves with ptrace
# isn't an appropriate solution though, since:
#
# 1.  Not all processes are ptraceable
# 2.  Most processes aren't allowed to chroot
# 3.  Processes don't like the inode number of their fds changing.
#     journald uses it to look-up which file descriptor was which
#     when it restarts itself.

-- [top] [command=gnome-terminal -x ./playdemo] [duration=60]

PoC - Demo

# Here's my demo I prepared earlier.
#
# It's actually a recording with the `script` command, since I'm
# nervous enough about doing a presentation without the prospect
# of demo failure, and taking extra time fiddling to get the demo
# ready.
#
# I start the demo in a version of a Baserock system with a two
# year old compiler.
#
# The script I've got my command in specifies to replace the
# mount at `/` with one that has a different btrfs subvolume.
#
# It fails the first time, as we need to have mount propagation
# of `/` to not be shared, for `pivot_root` to work.
#
# It's an untidy command as I didn't see much use in polishing a
# doomed approach.
#
# In the output spam you will see warnings that it can't migrate
# a bunch of processes because they can't be ptraced.
#
# But at the end you can see that I've got a more up to date
# compiler, and Baserock's tool for listing the current version
# says I'm using the new one.

-- [duration=30]
Making it better:

renameat2(…, RENAME_EXCHANGE)

# I mentioned earlier that one of the headaches in my Proof of
# Concept is that it needs to change the mounts for every
# process, some of which may be in different mount namespaces,
# which may have Slave or Private mount propagation, so you need
# to do the mount migration in all those namespaces too.
# 
# You can solve the need for changing the mount tree for every
# namespace and chroot by changing the state of the filesystem
# instead of the mount tree.
#
# You *can* do a whole filesystem update by creating a parallel
# tree and doing a renameat2(..., RENAME_EXCHANGE) the root
# directories.

-- [renameat2-process-file-pointers.png] [duration=5]

# However existing processes still have the old root, working
# directories and directory file descriptors
#
# The reason for this is that processes refer to the file that
# the tree points to, not the pointer in the tree.

-- [process-file-pointers-corrected.png] [duration=20]
Getting rid of ptrace:

New kernel interface for changing another process' file descriptors

# We could add a new kernel interface for altering process' open
# files so we don't need to ptrace, or require the process to
# have permissions to chroot, but that still doesn't solve the
# issue of the stat of directory fds changing.
#
# This also needs to be done atomically, since processes that
# communicate could get confused by having different views of the
# filesystem.

-- [duration=30]
Remaining approach 1 - File system transactions

# Another idea would be to add transactions to filesystems. 
#
# Btrfs has one form that can deadlock you if you're not careful,
# and there was a patch to specify a bunch of syscalls to run in
# a transaction but it didn't go anywhere.
#
# It was suggested that a better approach would be to have some
# form of syscall that merges two subvolumes, so your transaction
# is your changes to the snapshot, and they get atomically merged
# in.

-- [duration=40]
Remaining approach 2 - freeze all of userland during update

# You can get away without a fully atomic update if there's no
# concurrent users to worry about.
#
# You can freeze all processes in a freezer cgroup. You can't
# freeze the root cgroup, so you need all your services to be
# managed in cgroups, which makes systemd handy.
#
# So atomic operations could be faked by instructing systemd to
# freeze every service, then run a specified command before
# unfreezing all the services.
#
# This would give reasonable atomicity guarantees by:
# 1.  If we tell the bootloader to use a snapshot of the old
#     version before attempting to alter the current version,
#     so if we crash during update we're still left with a valid
#     version to boot from.
# 2.  Attempt to apply the update
# 3.  If the update failed roll back by using the contents of
#     the snapshot
# 4.  If it worked, remove the snapshot and tell the bootloader
#     to use your version again.

-- [duration=35]

Remaining approach 3 - Pivot pid 1 and hand over all services

# We could make pid 1 (systemd) `pivot_root` into the new root
# and start new versions of services, with the old services
# handing over their state, like an irssi, apache or journald
# graceful restart.
#
# I don't consider this to be a useful contender, since it
# requires the whole linux userland to be able to serialise state
# and hand over file descriptors to a new process.

-- [duration=25]
Remaining approach 4 - Proxy filesystem
# Alternatively we could have a proxy filesystem that we can swap the
# backing mount for atomically, and have it keep the inodes stable.
#
# AUFS nearly fits the bill, as it has some inode remapping, but
# it doesn't let you remove a layer that has open files, so you can't
# clean up the old version until every process has re-executed itself.

--
Summary

• Atomic Live updates would make updates more reliable
• Making a new mount tree, or atomically updating the root of a
  tree also doesn't work, since processes still refer to all the
  old directories.
• Possible future approaches are:
  1.  Filesystem transactions
  2.  Faking atomic updates by freezing userland
  3.  Only updating pid 1, and let it restart all the processes
  4.  A proxy filesystem that can atomically swap its backing fs
